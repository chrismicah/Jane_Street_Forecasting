{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735480a-a795-490f-bed6-c7422c317616",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb8dbaf-3db9-4569-8020-6be041c162bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_id', 'time_id', 'symbol_id', 'weight', 'feature_00', 'feature_01',\n",
      "       'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06',\n",
      "       'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11',\n",
      "       'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16',\n",
      "       'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21',\n",
      "       'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26',\n",
      "       'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31',\n",
      "       'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36',\n",
      "       'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41',\n",
      "       'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46',\n",
      "       'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51',\n",
      "       'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56',\n",
      "       'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61',\n",
      "       'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66',\n",
      "       'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71',\n",
      "       'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76',\n",
      "       'feature_77', 'feature_78', 'responder_0', 'responder_1', 'responder_2',\n",
      "       'responder_3', 'responder_4', 'responder_5', 'responder_6',\n",
      "       'responder_7', 'responder_8'],\n",
      "      dtype='object')\n",
      "date_id          int16\n",
      "time_id          int16\n",
      "symbol_id         int8\n",
      "weight         float32\n",
      "feature_00     float32\n",
      "                ...   \n",
      "responder_4    float32\n",
      "responder_5    float32\n",
      "responder_6    float32\n",
      "responder_7    float32\n",
      "responder_8    float32\n",
      "Length: 92, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training data for model development\n",
    "# train_path = 'jane-street-real-time-market-data-forecasting/train.parquet'\n",
    "# train_df = pd.read_parquet(train_path)\n",
    "sample_df = pd.read_parquet('jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0')\n",
    "\n",
    "# Display column names and data types\n",
    "print(sample_df.columns)\n",
    "print(sample_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f940b7-7dc5-4155-a4f5-0cc6a27a99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date_id  time_id  symbol_id    weight  feature_00  feature_01  \\\n",
      "1944205      169      848         19  3.438631         NaN         NaN   \n",
      "1944206      169      848         30  0.768528         NaN         NaN   \n",
      "1944207      169      848         33  1.354696         NaN         NaN   \n",
      "1944208      169      848         34  1.021797         NaN         NaN   \n",
      "1944209      169      848         38  1.570022         NaN         NaN   \n",
      "\n",
      "         feature_02  feature_03  feature_04  feature_05  ...  feature_78  \\\n",
      "1944205         NaN         NaN         NaN   -0.028087  ...   -0.166964   \n",
      "1944206         NaN         NaN         NaN   -0.022584  ...   -0.352810   \n",
      "1944207         NaN         NaN         NaN   -0.024804  ...   -0.239716   \n",
      "1944208         NaN         NaN         NaN   -0.016138  ...   -0.442859   \n",
      "1944209         NaN         NaN         NaN   -0.017634  ...   -0.174461   \n",
      "\n",
      "         responder_0  responder_1  responder_2  responder_3  responder_4  \\\n",
      "1944205     0.983339    -0.669860     0.272615    -3.676842    -1.221126   \n",
      "1944206     0.992615     0.961595     1.089402     0.796034     0.488380   \n",
      "1944207     1.701618     0.757672    -5.000000    -3.174266    -1.110790   \n",
      "1944208    -2.036891    -0.064228     1.919665     1.827681     0.872019   \n",
      "1944209     0.323230     0.018376    -3.457667    -0.305218    -0.181438   \n",
      "\n",
      "         responder_5  responder_6  responder_7  responder_8  \n",
      "1944205     1.070584     0.465345     0.207483     0.874975  \n",
      "1944206     1.846634    -0.088542    -0.008324    -0.153451  \n",
      "1944207    -3.349107    -0.407801    -0.185842    -0.931004  \n",
      "1944208     3.248694     0.254584     0.090288     0.434726  \n",
      "1944209    -0.791345     0.347400     0.241875     0.987731  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sample_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd4ba41-197a-4d77-9027-66b06db05cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_00    1944210\n",
      "feature_01    1944210\n",
      "feature_02    1944210\n",
      "feature_03    1944210\n",
      "feature_04    1944210\n",
      "feature_08      16980\n",
      "feature_15      54992\n",
      "feature_16         63\n",
      "feature_17       9232\n",
      "feature_18         59\n",
      "feature_19         59\n",
      "feature_21    1944210\n",
      "feature_26    1944210\n",
      "feature_27    1944210\n",
      "feature_31    1944210\n",
      "feature_32      21737\n",
      "feature_33      21737\n",
      "feature_39     324732\n",
      "feature_40      38328\n",
      "feature_41      97113\n",
      "feature_42     324732\n",
      "feature_43      38328\n",
      "feature_44      97113\n",
      "feature_45     166374\n",
      "feature_46     166374\n",
      "feature_47         87\n",
      "feature_50     293120\n",
      "feature_51       2290\n",
      "feature_52      64120\n",
      "feature_53     293120\n",
      "feature_54       2290\n",
      "feature_55      64120\n",
      "feature_56         59\n",
      "feature_57         59\n",
      "feature_58      21732\n",
      "feature_62     153999\n",
      "feature_63     133274\n",
      "feature_64     136458\n",
      "feature_65     166374\n",
      "feature_66     166374\n",
      "feature_73      21732\n",
      "feature_74      21732\n",
      "feature_75         16\n",
      "feature_76         16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_summary = sample_df.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])  # Show columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233737e7-f620-48b4-8b40-b06df21f3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define paths\n",
    "base_path = 'jane-street-real-time-market-data-forecasting/train.parquet'\n",
    "all_partitions = [os.path.join(base_path, f'partition_id={i}') for i in range(10)]  # Adjust the range if there are more partitions\n",
    "\n",
    "# Columns for encoding, imputation, and scaling\n",
    "feature_columns = [f'feature_{i:02}' for i in range(79)]\n",
    "responder_columns = [f'responder_{i}' for i in range(9)]\n",
    "id_columns = ['date_id', 'time_id', 'symbol_id']\n",
    "weight_column = ['weight']\n",
    "\n",
    "# Preprocessing function for each partition\n",
    "def preprocess_partition(partition_path):\n",
    "    # Load data\n",
    "    df = pd.read_parquet(partition_path)\n",
    "    \n",
    "    # Handle missing values with KNN Imputer for feature columns\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    df[feature_columns] = knn_imputer.fit_transform(df[feature_columns])\n",
    "\n",
    "    # Cyclic Encoding for time_id (if it's cyclical, e.g., hourly)\n",
    "    df['time_sin'] = np.sin(2 * np.pi * df['time_id'] / df['time_id'].max())\n",
    "    df['time_cos'] = np.cos(2 * np.pi * df['time_id'] / df['time_id'].max())\n",
    "    \n",
    "    # Encode symbol_id as categorical codes\n",
    "    df['symbol_id_encoded'] = df['symbol_id'].astype('category').cat.codes\n",
    "    \n",
    "    # Scaling for feature columns and weight column\n",
    "    scaler = StandardScaler()\n",
    "    df[feature_columns + weight_column] = scaler.fit_transform(df[feature_columns + weight_column])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process each partition and concatenate the results\n",
    "processed_data = pd.concat([preprocess_partition(part) for part in all_partitions], ignore_index=True)\n",
    "\n",
    "# Optional: Save the processed data to a file for future use\n",
    "processed_data.to_parquet('processed_data.parquet', index=False)\n",
    "\n",
    "print(\"Data preprocessing completed and saved to 'processed_data.parquet'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979edcc8-3652-4c54-b024-db10dcc1cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the main dataset directory\n",
    "base_path = 'jane-street-real-time-market-data-forecasting/train.parquet'\n",
    "\n",
    "# Adjust this list based on the exact names of your Parquet files\n",
    "all_partitions = [os.path.join(base_path, f'partition_id={i}') for i in range(10)]  # Adjust range if more partitions exist\n",
    "\n",
    "# Concatenate all Parquet partitions\n",
    "# Load each partition and concatenate them into a single DataFrame\n",
    "all_data = pd.concat([pd.read_parquet(part) for part in all_partitions], ignore_index=True)\n",
    "\n",
    "# Optional: Save the concatenated DataFrame to a single file\n",
    "# all_data.to_parquet('concatenated_data.parquet', index=False)\n",
    "\n",
    "# print(\"Concatenation completed and saved to 'concatenated_data.parquet'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a2a1af-13fa-4ca2-ba19-64188ec65474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (47127338, 92)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the DataFrame:\", all_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2804a1-b4e1-42b2-b57b-15da3e1ff3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47127338 entries, 0 to 47127337\n",
      "Data columns (total 92 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   date_id      int16  \n",
      " 1   time_id      int16  \n",
      " 2   symbol_id    int8   \n",
      " 3   weight       float32\n",
      " 4   feature_00   float32\n",
      " 5   feature_01   float32\n",
      " 6   feature_02   float32\n",
      " 7   feature_03   float32\n",
      " 8   feature_04   float32\n",
      " 9   feature_05   float32\n",
      " 10  feature_06   float32\n",
      " 11  feature_07   float32\n",
      " 12  feature_08   float32\n",
      " 13  feature_09   int8   \n",
      " 14  feature_10   int8   \n",
      " 15  feature_11   int16  \n",
      " 16  feature_12   float32\n",
      " 17  feature_13   float32\n",
      " 18  feature_14   float32\n",
      " 19  feature_15   float32\n",
      " 20  feature_16   float32\n",
      " 21  feature_17   float32\n",
      " 22  feature_18   float32\n",
      " 23  feature_19   float32\n",
      " 24  feature_20   float32\n",
      " 25  feature_21   float32\n",
      " 26  feature_22   float32\n",
      " 27  feature_23   float32\n",
      " 28  feature_24   float32\n",
      " 29  feature_25   float32\n",
      " 30  feature_26   float32\n",
      " 31  feature_27   float32\n",
      " 32  feature_28   float32\n",
      " 33  feature_29   float32\n",
      " 34  feature_30   float32\n",
      " 35  feature_31   float32\n",
      " 36  feature_32   float32\n",
      " 37  feature_33   float32\n",
      " 38  feature_34   float32\n",
      " 39  feature_35   float32\n",
      " 40  feature_36   float32\n",
      " 41  feature_37   float32\n",
      " 42  feature_38   float32\n",
      " 43  feature_39   float32\n",
      " 44  feature_40   float32\n",
      " 45  feature_41   float32\n",
      " 46  feature_42   float32\n",
      " 47  feature_43   float32\n",
      " 48  feature_44   float32\n",
      " 49  feature_45   float32\n",
      " 50  feature_46   float32\n",
      " 51  feature_47   float32\n",
      " 52  feature_48   float32\n",
      " 53  feature_49   float32\n",
      " 54  feature_50   float32\n",
      " 55  feature_51   float32\n",
      " 56  feature_52   float32\n",
      " 57  feature_53   float32\n",
      " 58  feature_54   float32\n",
      " 59  feature_55   float32\n",
      " 60  feature_56   float32\n",
      " 61  feature_57   float32\n",
      " 62  feature_58   float32\n",
      " 63  feature_59   float32\n",
      " 64  feature_60   float32\n",
      " 65  feature_61   float32\n",
      " 66  feature_62   float32\n",
      " 67  feature_63   float32\n",
      " 68  feature_64   float32\n",
      " 69  feature_65   float32\n",
      " 70  feature_66   float32\n",
      " 71  feature_67   float32\n",
      " 72  feature_68   float32\n",
      " 73  feature_69   float32\n",
      " 74  feature_70   float32\n",
      " 75  feature_71   float32\n",
      " 76  feature_72   float32\n",
      " 77  feature_73   float32\n",
      " 78  feature_74   float32\n",
      " 79  feature_75   float32\n",
      " 80  feature_76   float32\n",
      " 81  feature_77   float32\n",
      " 82  feature_78   float32\n",
      " 83  responder_0  float32\n",
      " 84  responder_1  float32\n",
      " 85  responder_2  float32\n",
      " 86  responder_3  float32\n",
      " 87  responder_4  float32\n",
      " 88  responder_5  float32\n",
      " 89  responder_6  float32\n",
      " 90  responder_7  float32\n",
      " 91  responder_8  float32\n",
      "dtypes: float32(86), int16(3), int8(3)\n",
      "memory usage: 15.5 GB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5edb2100-6e18-4b4d-a59a-0a0f140ab79d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 15.1 GiB for an array with shape (86, 47127338) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11976\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[1;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[0;32m  11734\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  11735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\n\u001b[0;32m  11736\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11739\u001b[0m     exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  11740\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m  11741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11742\u001b[0m \u001b[38;5;124;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[0;32m  11743\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11974\u001b[0m \u001b[38;5;124;03m    max            NaN      3.0\u001b[39;00m\n\u001b[0;32m  11975\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdescribe_ndframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11978\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescribe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:97\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[1;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     describer \u001b[38;5;241m=\u001b[39m DataFrameDescriber(\n\u001b[0;32m     92\u001b[0m         obj\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj),\n\u001b[0;32m     93\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m     94\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     95\u001b[0m     )\n\u001b[1;32m---> 97\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdescriber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:167\u001b[0m, in \u001b[0;36mDataFrameDescriber.describe\u001b[1;34m(self, percentiles)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\u001b[38;5;28mself\u001b[39m, percentiles: Sequence[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     ldesc: \u001b[38;5;28mlist\u001b[39m[Series] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, series \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:188\u001b[0m, in \u001b[0;36mDataFrameDescriber._select_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# when some numerics are found, keep only numerics\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     default_include: \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mDTypeLike] \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mnumber, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 188\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_include\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    190\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5091\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   5087\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   5089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 5091\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   5092\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[0;32m   5093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:604\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    601\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 604\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 15.1 GiB for an array with shape (86, 47127338) and data type float32"
     ]
    }
   ],
   "source": [
    "print(all_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a30f09f-1e14-4ac8-a3ea-06240e8bc199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_id              0\n",
      "time_id              0\n",
      "symbol_id            0\n",
      "weight               0\n",
      "feature_00     3182052\n",
      "                ...   \n",
      "responder_4          0\n",
      "responder_5          0\n",
      "responder_6          0\n",
      "responder_7          0\n",
      "responder_8          0\n",
      "Length: 92, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef49fdee-f736-4d72-9bb8-294076a5cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: Index(['feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04',\n",
      "       'feature_08', 'feature_15', 'feature_16', 'feature_17', 'feature_18',\n",
      "       'feature_19', 'feature_21', 'feature_26', 'feature_27', 'feature_31',\n",
      "       'feature_32', 'feature_33', 'feature_37', 'feature_39', 'feature_40',\n",
      "       'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45',\n",
      "       'feature_46', 'feature_47', 'feature_50', 'feature_51', 'feature_52',\n",
      "       'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57',\n",
      "       'feature_58', 'feature_62', 'feature_63', 'feature_64', 'feature_65',\n",
      "       'feature_66', 'feature_73', 'feature_74', 'feature_75', 'feature_76',\n",
      "       'feature_77', 'feature_78'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "missing_columns = all_data.columns[all_data.isnull().any()]\n",
    "print(\"Columns with missing values:\", missing_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6e033-f63e-4f7a-9fe7-51e6bca2da73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
